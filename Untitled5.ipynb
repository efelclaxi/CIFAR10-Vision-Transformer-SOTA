{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNCfTWYuA6xJBBpAzI7ysFd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"87221574339f47bab3f2e9b05d2b51fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43a11a4e6af046c5907b126bac5fc105","IPY_MODEL_e89389606d3b4b33b57fb96b556075f3","IPY_MODEL_5d775cdc80a645a68ab576ae8ae05794"],"layout":"IPY_MODEL_2b29211f961541c28f3d8a6fa3099f0c"}},"43a11a4e6af046c5907b126bac5fc105":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5adac2cd260f4809ab35803a7c25b146","placeholder":"‚Äã","style":"IPY_MODEL_9430c10030184616b34f6cbf8a99f71e","value":"model.safetensors:‚Äá100%"}},"e89389606d3b4b33b57fb96b556075f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_52e7404319dd4cc6adecab750f9fe195","max":346284714,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d4a31b4efb17447784bf45dcb8b8fe13","value":346284714}},"5d775cdc80a645a68ab576ae8ae05794":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b649c8e4c36742a99928fc524369be12","placeholder":"‚Äã","style":"IPY_MODEL_7d39046ac7e54e19b1a43e305f109602","value":"‚Äá346M/346M‚Äá[00:02&lt;00:00,‚Äá217MB/s]"}},"2b29211f961541c28f3d8a6fa3099f0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5adac2cd260f4809ab35803a7c25b146":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9430c10030184616b34f6cbf8a99f71e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52e7404319dd4cc6adecab750f9fe195":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4a31b4efb17447784bf45dcb8b8fe13":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b649c8e4c36742a99928fc524369be12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d39046ac7e54e19b1a43e305f109602":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install --upgrade timm torch torchvision matplotlib scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcRhel659a7B","executionInfo":{"status":"ok","timestamp":1767112385498,"user_tz":-180,"elapsed":7264,"user":{"displayName":"Hakan Aksoy","userId":"06845427660325046464"}},"outputId":"2cc2be39-1a9b-418e-e77a-ecf2d15cff26"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.22)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.8)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.8.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.7.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n","Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: joblib>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n","Requirement already satisfied: threadpoolctl>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.11.12)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import timm\n","from timm.data.mixup import Mixup\n","from timm.loss import SoftTargetCrossEntropy\n","import numpy as np\n","import random\n","import time\n","import os\n","import matplotlib.pyplot as plt\n","from torch.amp import autocast, GradScaler\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import gc\n","\n","# --- TEMƒ∞ZLƒ∞K ---\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","# --- KONFƒ∞G√úRASYON ---\n","class Config:\n","    seed = 42\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    # ƒ∞LK STRATEJƒ∞: ViT-Base (ImageNet-21k Pretrained)\n","    # Bu model CIFAR-10 i√ßin \"tank\" gibidir. Saƒülam ve g√º√ßl√º.\n","    model_name = 'vit_base_patch16_224.augreg_in21k_ft_in1k'\n","    img_size = 224\n","    num_classes = 10\n","\n","    # T4 GPU i√ßin G√ºvenli Ayarlar\n","    batch_size = 64        # SAM olmadƒ±ƒüƒ± i√ßin batch'i y√ºkselttik (Hƒ±zlƒ± eƒüitim)\n","    epochs = 7             # 7 Epoch'ta %98'i g√∂r√ºr√ºz\n","\n","    lr = 1e-4              # AdamW i√ßin ideal hƒ±z\n","    weight_decay = 0.05\n","\n","    # Mixup & Cutmix (Ezberlemeyi √∂nler, skoru artƒ±rƒ±r)\n","    mixup_alpha = 0.8\n","    cutmix_alpha = 1.0\n","    mixup_prob = 1.0\n","\n","cfg = Config()\n","\n","# --- REPRODUCIBILITY ---\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","set_seed(cfg.seed)\n","print(f\"Sistem Hazƒ±r: {cfg.device} | Model: {cfg.model_name}\")\n","\n","# --- DATA PIPELINE ---\n","mean = (0.5, 0.5, 0.5)\n","std = (0.5, 0.5, 0.5)\n","\n","transform_train = transforms.Compose([\n","    transforms.Resize((cfg.img_size, cfg.img_size), interpolation=transforms.InterpolationMode.BICUBIC),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandAugment(num_ops=2, magnitude=9), # Otomatik Veri Zenginle≈ütirme\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std)\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize((cfg.img_size, cfg.img_size), interpolation=transforms.InterpolationMode.BICUBIC),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std)\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=cfg.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=cfg.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n","\n","# --- MODEL SETUP ---\n","print(\"Model Y√ºkleniyor...\")\n","model = timm.create_model(cfg.model_name, pretrained=True, num_classes=cfg.num_classes)\n","model = model.to(cfg.device)\n","\n","# --- OPTIMIZER (ADAMW - G√ºvenli Liman) ---\n","# SAM yerine standart AdamW kullanƒ±yoruz. Daha hƒ±zlƒ± ve hatasƒ±z.\n","optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.epochs)\n","\n","# --- MIXUP SETUP ---\n","mixup_fn = Mixup(\n","    mixup_alpha=cfg.mixup_alpha,\n","    cutmix_alpha=cfg.cutmix_alpha,\n","    prob=cfg.mixup_prob,\n","    switch_prob=0.5,\n","    mode='batch',\n","    label_smoothing=0.1,\n","    num_classes=cfg.num_classes\n",")\n","\n","# Mixup olduƒüu i√ßin SoftTarget kullanƒ±yoruz\n","criterion_train = SoftTargetCrossEntropy()\n","criterion_test = nn.CrossEntropyLoss()\n","scaler = GradScaler('cuda')\n","\n","# --- TRAINING LOOP (Standart & G√ºvenli) ---\n","def train_one_epoch(epoch):\n","    model.train()\n","    running_loss = 0.0\n","\n","    start_time = time.time()\n","\n","    for i, (inputs, targets) in enumerate(trainloader):\n","        inputs, targets = inputs.to(cfg.device), targets.to(cfg.device)\n","\n","        # Mixup Uygula\n","        inputs, targets = mixup_fn(inputs, targets)\n","\n","        optimizer.zero_grad()\n","\n","        with autocast('cuda'):\n","            outputs = model(inputs)\n","            loss = criterion_train(outputs, targets)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item()\n","\n","        if i % 100 == 0 and i > 0:\n","            print(f\"  Step [{i}/{len(trainloader)}] | Loss: {loss.item():.4f}\")\n","\n","    return running_loss / len(trainloader), time.time() - start_time\n","\n","# --- EVALUATION (TTA) ---\n","@torch.no_grad()\n","def evaluate_tta():\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    print(\"Test ediliyor (TTA)...\")\n","    for inputs, targets in testloader:\n","        inputs, targets = inputs.to(cfg.device), targets.to(cfg.device)\n","        with autocast('cuda'):\n","            # 1. Normal Tahmin\n","            out1 = model(inputs)\n","            # 2. Ters √áevrilmi≈ü (Flip) Tahmin\n","            out2 = model(torch.flip(inputs, dims=[3]))\n","            # Ortalamasƒ±\n","            probs = (torch.softmax(out1, dim=1) + torch.softmax(out2, dim=1)) / 2\n","\n","        _, predicted = probs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","    return 100. * correct / total\n","\n","# --- MAIN LOOP ---\n","best_acc = 0.0\n","\n","for epoch in range(cfg.epochs):\n","    train_loss, duration = train_one_epoch(epoch)\n","    test_acc = evaluate_tta()\n","    scheduler.step()\n","\n","    print(f\"Epoch [{epoch+1}/{cfg.epochs}] | S√ºre: {duration:.0f}s\")\n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Test Acc (TTA): {test_acc:.2f}%\")\n","\n","    if test_acc > best_acc:\n","        best_acc = test_acc\n","        torch.save(model.state_dict(), 'sota_cifar10_best.pth')\n","        print(\"üèÜ Yeni En ƒ∞yi Model Kaydedildi!\")\n","\n","print(f\"\\nEƒüitim Tamamlandƒ±. Final SOTA Skoru: {best_acc:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["87221574339f47bab3f2e9b05d2b51fd","43a11a4e6af046c5907b126bac5fc105","e89389606d3b4b33b57fb96b556075f3","5d775cdc80a645a68ab576ae8ae05794","2b29211f961541c28f3d8a6fa3099f0c","5adac2cd260f4809ab35803a7c25b146","9430c10030184616b34f6cbf8a99f71e","52e7404319dd4cc6adecab750f9fe195","d4a31b4efb17447784bf45dcb8b8fe13","b649c8e4c36742a99928fc524369be12","7d39046ac7e54e19b1a43e305f109602"]},"id":"3Uy27hoBG__I","executionInfo":{"status":"ok","timestamp":1767115787490,"user_tz":-180,"elapsed":3337043,"user":{"displayName":"Hakan Aksoy","userId":"06845427660325046464"}},"outputId":"c9b5ad4f-0de2-4e69-891f-00015f36e215"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Sistem Hazƒ±r: cuda | Model: vit_base_patch16_224.augreg_in21k_ft_in1k\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170M/170M [00:03<00:00, 43.2MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Model Y√ºkleniyor...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87221574339f47bab3f2e9b05d2b51fd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["  Step [100/782] | Loss: 1.0393\n","  Step [200/782] | Loss: 1.5174\n","  Step [300/782] | Loss: 1.2415\n","  Step [400/782] | Loss: 0.7669\n","  Step [500/782] | Loss: 1.6730\n","  Step [600/782] | Loss: 1.6284\n","  Step [700/782] | Loss: 1.4346\n","Test ediliyor (TTA)...\n","Epoch [1/7] | S√ºre: 395s\n","Train Loss: 1.3399\n","Test Acc (TTA): 96.57%\n","üèÜ Yeni En ƒ∞yi Model Kaydedildi!\n","  Step [100/782] | Loss: 1.4865\n","  Step [200/782] | Loss: 1.1772\n","  Step [300/782] | Loss: 0.5851\n","  Step [400/782] | Loss: 1.0668\n","  Step [500/782] | Loss: 1.4792\n","  Step [600/782] | Loss: 0.9036\n","  Step [700/782] | Loss: 0.6178\n","Test ediliyor (TTA)...\n","Epoch [2/7] | S√ºre: 419s\n","Train Loss: 1.2075\n","Test Acc (TTA): 96.82%\n","üèÜ Yeni En ƒ∞yi Model Kaydedildi!\n","  Step [100/782] | Loss: 1.1460\n","  Step [200/782] | Loss: 0.6677\n","  Step [300/782] | Loss: 1.2151\n","  Step [400/782] | Loss: 1.2593\n","  Step [500/782] | Loss: 1.0499\n","  Step [600/782] | Loss: 1.1506\n","  Step [700/782] | Loss: 0.9847\n","Test ediliyor (TTA)...\n","Epoch [3/7] | S√ºre: 408s\n","Train Loss: 1.1659\n","Test Acc (TTA): 97.47%\n","üèÜ Yeni En ƒ∞yi Model Kaydedildi!\n","  Step [100/782] | Loss: 1.3827\n","  Step [200/782] | Loss: 1.6290\n","  Step [300/782] | Loss: 1.1451\n","  Step [400/782] | Loss: 0.5653\n","  Step [500/782] | Loss: 1.1209\n","  Step [600/782] | Loss: 0.9108\n","  Step [700/782] | Loss: 1.1950\n","Test ediliyor (TTA)...\n","Epoch [4/7] | S√ºre: 409s\n","Train Loss: 1.1046\n","Test Acc (TTA): 98.11%\n","üèÜ Yeni En ƒ∞yi Model Kaydedildi!\n","  Step [100/782] | Loss: 0.8693\n","  Step [200/782] | Loss: 1.2509\n","  Step [300/782] | Loss: 1.3122\n","  Step [400/782] | Loss: 1.2896\n","  Step [500/782] | Loss: 1.0638\n","  Step [600/782] | Loss: 1.2821\n","  Step [700/782] | Loss: 1.0788\n","Test ediliyor (TTA)...\n","Epoch [5/7] | S√ºre: 409s\n","Train Loss: 1.0692\n","Test Acc (TTA): 98.25%\n","üèÜ Yeni En ƒ∞yi Model Kaydedildi!\n","  Step [100/782] | Loss: 0.6947\n","  Step [200/782] | Loss: 1.4144\n","  Step [300/782] | Loss: 0.8819\n","  Step [400/782] | Loss: 1.0427\n","  Step [500/782] | Loss: 1.1392\n","  Step [600/782] | Loss: 1.0857\n","  Step [700/782] | Loss: 1.0956\n","Test ediliyor (TTA)...\n","Epoch [6/7] | S√ºre: 410s\n","Train Loss: 1.0188\n","Test Acc (TTA): 98.87%\n","üèÜ Yeni En ƒ∞yi Model Kaydedildi!\n","  Step [100/782] | Loss: 1.1289\n","  Step [200/782] | Loss: 1.1742\n","  Step [300/782] | Loss: 0.8288\n","  Step [400/782] | Loss: 1.0524\n","  Step [500/782] | Loss: 1.2415\n","  Step [600/782] | Loss: 1.2052\n","  Step [700/782] | Loss: 1.0457\n","Test ediliyor (TTA)...\n","Epoch [7/7] | S√ºre: 410s\n","Train Loss: 1.0011\n","Test Acc (TTA): 98.86%\n","\n","Eƒüitim Tamamlandƒ±. Final SOTA Skoru: 98.87%\n"]}]}]}